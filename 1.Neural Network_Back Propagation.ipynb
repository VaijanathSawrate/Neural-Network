{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create your first MLP in Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 9)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "# Load pima indians dataset\n",
    "dataset = numpy.loadtxt(\"D:\\DATA_science\\Data_sets\\\\pima-indians-diabetes.data.csv\", delimiter = ',')\n",
    "# Split into input(X) and output(Y) variables\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim = 8, activation = 'relu'))\n",
    "model.add(Dense(8, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile Model\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "52/52 [==============================] - 2s 15ms/step - loss: 14.9795 - accuracy: 0.4664 - val_loss: 5.6066 - val_accuracy: 0.6142\n",
      "Epoch 2/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 6.3832 - accuracy: 0.5714 - val_loss: 1.9037 - val_accuracy: 0.6024\n",
      "Epoch 3/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.8668 - accuracy: 0.5751 - val_loss: 1.4185 - val_accuracy: 0.5748\n",
      "Epoch 4/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.6679 - accuracy: 0.5705 - val_loss: 1.1644 - val_accuracy: 0.6024\n",
      "Epoch 5/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2202 - accuracy: 0.6028 - val_loss: 1.2518 - val_accuracy: 0.5118\n",
      "Epoch 6/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.2192 - accuracy: 0.5781 - val_loss: 1.0885 - val_accuracy: 0.5551\n",
      "Epoch 7/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 1.1519 - accuracy: 0.5635 - val_loss: 0.9971 - val_accuracy: 0.5748\n",
      "Epoch 8/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.0792 - accuracy: 0.6048 - val_loss: 0.9746 - val_accuracy: 0.5669\n",
      "Epoch 9/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 1.0019 - accuracy: 0.5880 - val_loss: 0.9078 - val_accuracy: 0.5866\n",
      "Epoch 10/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.8345 - accuracy: 0.5963 - val_loss: 0.9407 - val_accuracy: 0.5591\n",
      "Epoch 11/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.7866 - accuracy: 0.6298 - val_loss: 0.8715 - val_accuracy: 0.5945\n",
      "Epoch 12/150\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 0.7923 - accuracy: 0.6354 - val_loss: 0.8468 - val_accuracy: 0.5945\n",
      "Epoch 13/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.7705 - accuracy: 0.6384 - val_loss: 0.8350 - val_accuracy: 0.5787\n",
      "Epoch 14/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.7425 - accuracy: 0.6284 - val_loss: 0.8978 - val_accuracy: 0.5276\n",
      "Epoch 15/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.7138 - accuracy: 0.6350 - val_loss: 0.7909 - val_accuracy: 0.6142\n",
      "Epoch 16/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.6888 - accuracy: 0.6496 - val_loss: 0.7830 - val_accuracy: 0.6260\n",
      "Epoch 17/150\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 0.7089 - accuracy: 0.6379 - val_loss: 0.7757 - val_accuracy: 0.6339\n",
      "Epoch 18/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.6159 - accuracy: 0.6936 - val_loss: 0.8600 - val_accuracy: 0.6181\n",
      "Epoch 19/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.6607 - accuracy: 0.6909 - val_loss: 0.7455 - val_accuracy: 0.6260\n",
      "Epoch 20/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.6451 - accuracy: 0.6861 - val_loss: 0.7492 - val_accuracy: 0.6299\n",
      "Epoch 21/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.6413 - accuracy: 0.6743 - val_loss: 0.8213 - val_accuracy: 0.5748\n",
      "Epoch 22/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.6547 - accuracy: 0.6628 - val_loss: 0.7229 - val_accuracy: 0.6220\n",
      "Epoch 23/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.6532 - accuracy: 0.6374 - val_loss: 0.7432 - val_accuracy: 0.6299\n",
      "Epoch 24/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.6442 - accuracy: 0.6815 - val_loss: 0.7304 - val_accuracy: 0.6024\n",
      "Epoch 25/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.6288 - accuracy: 0.6838 - val_loss: 0.7040 - val_accuracy: 0.6457\n",
      "Epoch 26/150\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 0.6348 - accuracy: 0.6933 - val_loss: 0.7047 - val_accuracy: 0.6260\n",
      "Epoch 27/150\n",
      "52/52 [==============================] - 0s 6ms/step - loss: 0.5809 - accuracy: 0.7078 - val_loss: 0.7517 - val_accuracy: 0.5591\n",
      "Epoch 28/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.6300 - accuracy: 0.6994 - val_loss: 0.7069 - val_accuracy: 0.6417\n",
      "Epoch 29/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.6035 - accuracy: 0.7112 - val_loss: 0.7171 - val_accuracy: 0.6142\n",
      "Epoch 30/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.6475 - accuracy: 0.6662 - val_loss: 0.6729 - val_accuracy: 0.6457\n",
      "Epoch 31/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.5346 - accuracy: 0.7241 - val_loss: 0.6828 - val_accuracy: 0.6535\n",
      "Epoch 32/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.6098 - accuracy: 0.6803 - val_loss: 0.7227 - val_accuracy: 0.6260\n",
      "Epoch 33/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.6075 - accuracy: 0.7091 - val_loss: 0.6871 - val_accuracy: 0.6063\n",
      "Epoch 34/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5454 - accuracy: 0.7446 - val_loss: 0.6643 - val_accuracy: 0.6575\n",
      "Epoch 35/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5820 - accuracy: 0.7093 - val_loss: 0.6717 - val_accuracy: 0.6535\n",
      "Epoch 36/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6292 - accuracy: 0.7024 - val_loss: 0.6497 - val_accuracy: 0.6457\n",
      "Epoch 37/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5267 - accuracy: 0.7575 - val_loss: 0.6690 - val_accuracy: 0.6535\n",
      "Epoch 38/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.6136 - accuracy: 0.7355 - val_loss: 0.7285 - val_accuracy: 0.6654\n",
      "Epoch 39/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5547 - accuracy: 0.7237 - val_loss: 0.6526 - val_accuracy: 0.6693\n",
      "Epoch 40/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5783 - accuracy: 0.7039 - val_loss: 0.6374 - val_accuracy: 0.6693\n",
      "Epoch 41/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.5541 - accuracy: 0.7131 - val_loss: 0.6582 - val_accuracy: 0.6614\n",
      "Epoch 42/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5966 - accuracy: 0.7055 - val_loss: 0.6554 - val_accuracy: 0.6260\n",
      "Epoch 43/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5628 - accuracy: 0.6990 - val_loss: 0.6303 - val_accuracy: 0.6614\n",
      "Epoch 44/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.5723 - accuracy: 0.6930 - val_loss: 0.6917 - val_accuracy: 0.6378\n",
      "Epoch 45/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5327 - accuracy: 0.7500 - val_loss: 0.6531 - val_accuracy: 0.6457\n",
      "Epoch 46/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5831 - accuracy: 0.6860 - val_loss: 0.6505 - val_accuracy: 0.6299\n",
      "Epoch 47/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5256 - accuracy: 0.7403 - val_loss: 0.6455 - val_accuracy: 0.6614\n",
      "Epoch 48/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5615 - accuracy: 0.7240 - val_loss: 0.6310 - val_accuracy: 0.6339\n",
      "Epoch 49/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5400 - accuracy: 0.7269 - val_loss: 0.6489 - val_accuracy: 0.6575\n",
      "Epoch 50/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5391 - accuracy: 0.7214 - val_loss: 0.6387 - val_accuracy: 0.6693\n",
      "Epoch 51/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5820 - accuracy: 0.6888 - val_loss: 0.6343 - val_accuracy: 0.6417\n",
      "Epoch 52/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.5657 - accuracy: 0.7229 - val_loss: 0.6658 - val_accuracy: 0.6181\n",
      "Epoch 53/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5439 - accuracy: 0.7341 - val_loss: 0.6510 - val_accuracy: 0.6693\n",
      "Epoch 54/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5914 - accuracy: 0.6734 - val_loss: 0.6361 - val_accuracy: 0.6496\n",
      "Epoch 55/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5738 - accuracy: 0.7112 - val_loss: 0.6183 - val_accuracy: 0.6732\n",
      "Epoch 56/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5495 - accuracy: 0.7361 - val_loss: 0.6225 - val_accuracy: 0.6535\n",
      "Epoch 57/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.5684 - accuracy: 0.7078 - val_loss: 0.6412 - val_accuracy: 0.6772\n",
      "Epoch 58/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5344 - accuracy: 0.7231 - val_loss: 0.6388 - val_accuracy: 0.6457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5365 - accuracy: 0.7148 - val_loss: 0.6358 - val_accuracy: 0.6732\n",
      "Epoch 60/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.5391 - accuracy: 0.7296 - val_loss: 0.6356 - val_accuracy: 0.6772\n",
      "Epoch 61/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5519 - accuracy: 0.7297 - val_loss: 0.6265 - val_accuracy: 0.6575\n",
      "Epoch 62/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5353 - accuracy: 0.7208 - val_loss: 0.6303 - val_accuracy: 0.6850\n",
      "Epoch 63/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.5309 - accuracy: 0.7318 - val_loss: 0.6386 - val_accuracy: 0.6339\n",
      "Epoch 64/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5290 - accuracy: 0.7429 - val_loss: 0.6320 - val_accuracy: 0.6654\n",
      "Epoch 65/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5207 - accuracy: 0.7560 - val_loss: 0.6218 - val_accuracy: 0.6614\n",
      "Epoch 66/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5321 - accuracy: 0.7395 - val_loss: 0.6156 - val_accuracy: 0.6850\n",
      "Epoch 67/150\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.5364 - accuracy: 0.7406 - val_loss: 0.6301 - val_accuracy: 0.6614\n",
      "Epoch 68/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5362 - accuracy: 0.7481 - val_loss: 0.6106 - val_accuracy: 0.6575\n",
      "Epoch 69/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5166 - accuracy: 0.7431 - val_loss: 0.6645 - val_accuracy: 0.6220\n",
      "Epoch 70/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5187 - accuracy: 0.7296 - val_loss: 0.6104 - val_accuracy: 0.6693\n",
      "Epoch 71/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5109 - accuracy: 0.7643 - val_loss: 0.6199 - val_accuracy: 0.6929\n",
      "Epoch 72/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5212 - accuracy: 0.7556 - val_loss: 0.6732 - val_accuracy: 0.6102\n",
      "Epoch 73/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5177 - accuracy: 0.7396 - val_loss: 0.6053 - val_accuracy: 0.6732\n",
      "Epoch 74/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5312 - accuracy: 0.7215 - val_loss: 0.5999 - val_accuracy: 0.6890\n",
      "Epoch 75/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.4997 - accuracy: 0.7612 - val_loss: 0.5920 - val_accuracy: 0.6890\n",
      "Epoch 76/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5822 - accuracy: 0.7180 - val_loss: 0.6072 - val_accuracy: 0.6693\n",
      "Epoch 77/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5314 - accuracy: 0.7250 - val_loss: 0.6390 - val_accuracy: 0.6339\n",
      "Epoch 78/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5106 - accuracy: 0.7414 - val_loss: 0.5935 - val_accuracy: 0.6772\n",
      "Epoch 79/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5255 - accuracy: 0.7371 - val_loss: 0.6022 - val_accuracy: 0.7047\n",
      "Epoch 80/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5666 - accuracy: 0.7054 - val_loss: 0.6071 - val_accuracy: 0.6969\n",
      "Epoch 81/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5089 - accuracy: 0.7341 - val_loss: 0.6195 - val_accuracy: 0.6811\n",
      "Epoch 82/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5131 - accuracy: 0.7683 - val_loss: 0.5778 - val_accuracy: 0.6693\n",
      "Epoch 83/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5091 - accuracy: 0.7727 - val_loss: 0.5843 - val_accuracy: 0.6654\n",
      "Epoch 84/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.4937 - accuracy: 0.7605 - val_loss: 0.6332 - val_accuracy: 0.6732\n",
      "Epoch 85/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5153 - accuracy: 0.7511 - val_loss: 0.6042 - val_accuracy: 0.6969\n",
      "Epoch 86/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5490 - accuracy: 0.7528 - val_loss: 0.5959 - val_accuracy: 0.6811\n",
      "Epoch 87/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5108 - accuracy: 0.7623 - val_loss: 0.5824 - val_accuracy: 0.7008\n",
      "Epoch 88/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5155 - accuracy: 0.7517 - val_loss: 0.5902 - val_accuracy: 0.6850\n",
      "Epoch 89/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5335 - accuracy: 0.7294 - val_loss: 0.5868 - val_accuracy: 0.6890\n",
      "Epoch 90/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5071 - accuracy: 0.7404 - val_loss: 0.6562 - val_accuracy: 0.6260\n",
      "Epoch 91/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5394 - accuracy: 0.7495 - val_loss: 0.5768 - val_accuracy: 0.6850\n",
      "Epoch 92/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5009 - accuracy: 0.7569 - val_loss: 0.5825 - val_accuracy: 0.6811\n",
      "Epoch 93/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5082 - accuracy: 0.7527 - val_loss: 0.6106 - val_accuracy: 0.6732\n",
      "Epoch 94/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5254 - accuracy: 0.7356 - val_loss: 0.5873 - val_accuracy: 0.7126\n",
      "Epoch 95/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5032 - accuracy: 0.7381 - val_loss: 0.5885 - val_accuracy: 0.7047\n",
      "Epoch 96/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5161 - accuracy: 0.7449 - val_loss: 0.5823 - val_accuracy: 0.6772\n",
      "Epoch 97/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5001 - accuracy: 0.7521 - val_loss: 0.5925 - val_accuracy: 0.7047\n",
      "Epoch 98/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5066 - accuracy: 0.7508 - val_loss: 0.5866 - val_accuracy: 0.6693\n",
      "Epoch 99/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5229 - accuracy: 0.7341 - val_loss: 0.5888 - val_accuracy: 0.6929\n",
      "Epoch 100/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5194 - accuracy: 0.7357 - val_loss: 0.5855 - val_accuracy: 0.7047\n",
      "Epoch 101/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5055 - accuracy: 0.7525 - val_loss: 0.5769 - val_accuracy: 0.6929\n",
      "Epoch 102/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5274 - accuracy: 0.7295 - val_loss: 0.5677 - val_accuracy: 0.7008\n",
      "Epoch 103/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5322 - accuracy: 0.7353 - val_loss: 0.6264 - val_accuracy: 0.6850\n",
      "Epoch 104/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5357 - accuracy: 0.7704 - val_loss: 0.5868 - val_accuracy: 0.7047\n",
      "Epoch 105/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.4978 - accuracy: 0.7690 - val_loss: 0.5755 - val_accuracy: 0.6969\n",
      "Epoch 106/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5255 - accuracy: 0.7316 - val_loss: 0.5710 - val_accuracy: 0.7165\n",
      "Epoch 107/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5054 - accuracy: 0.7626 - val_loss: 0.5691 - val_accuracy: 0.6890\n",
      "Epoch 108/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5153 - accuracy: 0.7677 - val_loss: 0.5828 - val_accuracy: 0.6890\n",
      "Epoch 109/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.4922 - accuracy: 0.7640 - val_loss: 0.5968 - val_accuracy: 0.7008\n",
      "Epoch 110/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5207 - accuracy: 0.7437 - val_loss: 0.5656 - val_accuracy: 0.7047\n",
      "Epoch 111/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5137 - accuracy: 0.7456 - val_loss: 0.5834 - val_accuracy: 0.6890\n",
      "Epoch 112/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5235 - accuracy: 0.7387 - val_loss: 0.5723 - val_accuracy: 0.6850\n",
      "Epoch 113/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5363 - accuracy: 0.7567 - val_loss: 0.5758 - val_accuracy: 0.7008\n",
      "Epoch 114/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5171 - accuracy: 0.7596 - val_loss: 0.5682 - val_accuracy: 0.7047\n",
      "Epoch 115/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5327 - accuracy: 0.7614 - val_loss: 0.6074 - val_accuracy: 0.6772\n",
      "Epoch 116/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5003 - accuracy: 0.7508 - val_loss: 0.5775 - val_accuracy: 0.7244\n",
      "Epoch 117/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5145 - accuracy: 0.7497 - val_loss: 0.5688 - val_accuracy: 0.7165\n",
      "Epoch 118/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.4841 - accuracy: 0.7624 - val_loss: 0.5716 - val_accuracy: 0.6890\n",
      "Epoch 119/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.4965 - accuracy: 0.7566 - val_loss: 0.5824 - val_accuracy: 0.7165\n",
      "Epoch 120/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5147 - accuracy: 0.7523 - val_loss: 0.5636 - val_accuracy: 0.6929\n",
      "Epoch 121/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.4919 - accuracy: 0.7695 - val_loss: 0.5716 - val_accuracy: 0.7087\n",
      "Epoch 122/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5072 - accuracy: 0.7392 - val_loss: 0.5796 - val_accuracy: 0.7165\n",
      "Epoch 123/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5139 - accuracy: 0.7492 - val_loss: 0.5629 - val_accuracy: 0.7283\n",
      "Epoch 124/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5204 - accuracy: 0.7385 - val_loss: 0.6015 - val_accuracy: 0.7126\n",
      "Epoch 125/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.4828 - accuracy: 0.7380 - val_loss: 0.5608 - val_accuracy: 0.7283\n",
      "Epoch 126/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.4817 - accuracy: 0.7753 - val_loss: 0.5785 - val_accuracy: 0.6969\n",
      "Epoch 127/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5026 - accuracy: 0.7515 - val_loss: 0.5648 - val_accuracy: 0.6969\n",
      "Epoch 128/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5180 - accuracy: 0.7564 - val_loss: 0.5819 - val_accuracy: 0.7165\n",
      "Epoch 129/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5328 - accuracy: 0.7302 - val_loss: 0.5816 - val_accuracy: 0.7087\n",
      "Epoch 130/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.4875 - accuracy: 0.7587 - val_loss: 0.5745 - val_accuracy: 0.7087\n",
      "Epoch 131/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.4795 - accuracy: 0.7476 - val_loss: 0.5742 - val_accuracy: 0.7165\n",
      "Epoch 132/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.4714 - accuracy: 0.8009 - val_loss: 0.5502 - val_accuracy: 0.7087\n",
      "Epoch 133/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5030 - accuracy: 0.7539 - val_loss: 0.5595 - val_accuracy: 0.6929\n",
      "Epoch 134/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5094 - accuracy: 0.7427 - val_loss: 0.5873 - val_accuracy: 0.6772\n",
      "Epoch 135/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.4906 - accuracy: 0.7629 - val_loss: 0.5887 - val_accuracy: 0.6969\n",
      "Epoch 136/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.4887 - accuracy: 0.7723 - val_loss: 0.5525 - val_accuracy: 0.7165\n",
      "Epoch 137/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5045 - accuracy: 0.7613 - val_loss: 0.5590 - val_accuracy: 0.7008\n",
      "Epoch 138/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.4987 - accuracy: 0.7497 - val_loss: 0.5563 - val_accuracy: 0.7165\n",
      "Epoch 139/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.4740 - accuracy: 0.7437 - val_loss: 0.5579 - val_accuracy: 0.7244\n",
      "Epoch 140/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5150 - accuracy: 0.7295 - val_loss: 0.5727 - val_accuracy: 0.7283\n",
      "Epoch 141/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5122 - accuracy: 0.7413 - val_loss: 0.5599 - val_accuracy: 0.7205\n",
      "Epoch 142/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.4724 - accuracy: 0.7813 - val_loss: 0.5963 - val_accuracy: 0.6969\n",
      "Epoch 143/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5239 - accuracy: 0.7360 - val_loss: 0.5599 - val_accuracy: 0.7244\n",
      "Epoch 144/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.4853 - accuracy: 0.7535 - val_loss: 0.5884 - val_accuracy: 0.6929\n",
      "Epoch 145/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5276 - accuracy: 0.7340 - val_loss: 0.5534 - val_accuracy: 0.7008\n",
      "Epoch 146/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.4944 - accuracy: 0.7672 - val_loss: 0.6288 - val_accuracy: 0.6850\n",
      "Epoch 147/150\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.7696 - val_loss: 0.5416 - val_accuracy: 0.7165\n",
      "Epoch 148/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.4740 - accuracy: 0.7738 - val_loss: 0.5653 - val_accuracy: 0.7126\n",
      "Epoch 149/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.4474 - accuracy: 0.7919 - val_loss: 0.5592 - val_accuracy: 0.7323\n",
      "Epoch 150/150\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5238 - accuracy: 0.7702 - val_loss: 0.5628 - val_accuracy: 0.7165\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x25d44d1fb80>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the Model\n",
    "model.fit(X, Y, validation_split = 0.33, epochs = 150, batch_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.7565\n",
      "accuracy: 75.65%\n"
     ]
    }
   ],
   "source": [
    "# evaulate the model\n",
    "scores = model.evaluate(X, Y)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
